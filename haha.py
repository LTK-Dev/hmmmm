import streamlit as st
import pandas as pd
import os
import google.generativeai as genai
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum
import json

# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt cho FAISS v√† LangChain
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_core.prompts import ChatPromptTemplate

# --- Data Classes v√† Enums ---
class AgentType(Enum):
    ROUTER = "router"
    PRODUCT_SPECIALIST = "product_specialist"
    GENERAL_CONSULTANT = "general_consultant"

@dataclass
class AgentResponse:
    content: str
    confidence: float
    agent_type: AgentType
    metadata: Dict[str, Any] = None

@dataclass
class TaskRequest:
    query: str
    context: List[str] = None
    metadata: Dict[str, Any] = None

# --- C·∫•u h√¨nh ---
PRODUCT_CSV_FILE = 'EKS.csv'
SCRIPT_CSV_FILE = 'EKS_ques.csv'
PRODUCT_FAISS_PATH = "faiss_index_product"
SCRIPT_FAISS_PATH = "faiss_index_script"
EMBEDDER_MODEL = 'intfloat/multilingual-e5-base'
GENERATIVE_MODEL = 'gemini-2.0-flash'

# --- Base Agent Class ---
class BaseAgent:
    def __init__(self, agent_type: AgentType, model: genai.GenerativeModel):
        self.agent_type = agent_type
        self.model = model
        self.name = agent_type.value
    
    def process(self, request: TaskRequest) -> AgentResponse:
        """Base method ƒë·ªÉ x·ª≠ l√Ω request - s·∫Ω ƒë∆∞·ª£c override b·ªüi c√°c agent con"""
        raise NotImplementedError("Subclasses must implement process method")
    
    def _generate_stream_response(self, prompt: str):
        """Helper method ƒë·ªÉ generate streaming response"""
        try:
            response_stream = self.model.generate_content(prompt, stream=True)
            for chunk in response_stream:
                if chunk.text:
                    yield chunk.text
        except Exception as e:
            st.error(f"L·ªói khi generate response t·ª´ {self.name}: {e}")
            yield f"Xin l·ªói, {self.name} g·∫∑p l·ªói khi x·ª≠ l√Ω y√™u c·∫ßu."

# --- Router Agent ---
class RouterAgent(BaseAgent):
    def __init__(self, model: genai.GenerativeModel):
        super().__init__(AgentType.ROUTER, model)
        self.routing_prompt = """
        B·∫°n l√† Router Agent c·ªßa h·ªá th·ªëng EKS AI Assistant. Nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch c√¢u h·ªèi v√† quy·∫øt ƒë·ªãnh agent n√†o s·∫Ω x·ª≠ l√Ω.

        **C√°c Agent c√≥ s·∫µn:**
        1. **product_specialist**: Chuy√™n gia s·∫£n ph·∫©m - x·ª≠ l√Ω c√¢u h·ªèi v·ªÅ:
           - Th√¥ng tin chi ti·∫øt s·∫£n ph·∫©m (c√¥ng d·ª•ng, th√†nh ph·∫ßn, c√°ch d√πng)
           - Ch·ªâ ƒë·ªãnh, ch·ªëng ch·ªâ ƒë·ªãnh c·ªßa s·∫£n ph·∫©m
           - B·∫£o qu·∫£n, l∆∞u √Ω khi s·ª≠ d·ª•ng
           - T√°c d·ª•ng ph·ª•, li·ªÅu l∆∞·ª£ng

        2. **general_consultant**: T∆∞ v·∫•n vi√™n chung - x·ª≠ l√Ω c√¢u h·ªèi v·ªÅ:
           - So s√°nh nhi·ªÅu s·∫£n ph·∫©m
           - Th√¥ng tin v·ªÅ c√¥ng ty, th∆∞∆°ng hi·ªáu
           - Ch√≠nh s√°ch, d·ªãch v·ª• kh√°ch h√†ng
           - ƒê·ªãa ch·ªâ mua h√†ng, li√™n h·ªá
           - C√¢u h·ªèi t·ªïng qu√°t v·ªÅ ng√†nh m·ªπ ph·∫©m

        **C√¢u h·ªèi c·∫ßn ph√¢n t√≠ch:**
        "{query}"

        **Y√™u c·∫ßu:**
        Tr·∫£ l·ªùi CH√çNH X√ÅC theo format JSON sau:
        {{
            "agent": "product_specialist" ho·∫∑c "general_consultant",
            "confidence": s·ªë t·ª´ 0.0 ƒë·∫øn 1.0,
            "reasoning": "l√Ω do ng·∫Øn g·ªçn cho quy·∫øt ƒë·ªãnh"
        }}

        CH·ªà tr·∫£ l·ªùi JSON, kh√¥ng th√™m text n√†o kh√°c.
        """
    
    def process(self, request: TaskRequest) -> Dict[str, Any]:
        """Ph√¢n t√≠ch v√† route c√¢u h·ªèi ƒë·∫øn agent ph√π h·ª£p"""
        try:
            prompt = self.routing_prompt.format(query=request.query)
            response = self.model.generate_content(prompt)
            
            # Parse JSON response
            routing_decision = json.loads(response.text.strip())
            
            return {
                'target_agent': routing_decision.get('agent', 'general_consultant'),
                'confidence': routing_decision.get('confidence', 0.5),
                'reasoning': routing_decision.get('reasoning', 'Ph√¢n t√≠ch t·ª± ƒë·ªông')
            }
            
        except json.JSONDecodeError:
            # Fallback n·∫øu JSON parsing th·∫•t b·∫°i
            st.warning("Router Agent tr·∫£ v·ªÅ format kh√¥ng ƒë√∫ng, s·ª≠ d·ª•ng fallback logic")
            return self._fallback_routing(request.query)
        except Exception as e:
            st.error(f"L·ªói Router Agent: {e}")
            return self._fallback_routing(request.query)
    
    def _fallback_routing(self, query: str) -> Dict[str, Any]:
        """Fallback routing logic n·∫øu AI routing th·∫•t b·∫°i"""
        query_lower = query.lower()
        
        product_keywords = ['s·∫£n ph·∫©m', 'c√¥ng d·ª•ng', 'th√†nh ph·∫ßn', 'c√°ch d√πng', 'ch·ªâ ƒë·ªãnh', 't√°c d·ª•ng']
        general_keywords = ['so s√°nh', 'c√¥ng ty', 'mua ·ªü ƒë√¢u', 'gi√°', 'ch√≠nh s√°ch']
        
        product_score = sum(1 for kw in product_keywords if kw in query_lower)
        general_score = sum(1 for kw in general_keywords if kw in query_lower)
        
        if product_score > general_score:
            return {'target_agent': 'product_specialist', 'confidence': 0.7, 'reasoning': 'Fallback: Ph√°t hi·ªán t·ª´ kh√≥a s·∫£n ph·∫©m'}
        else:
            return {'target_agent': 'general_consultant', 'confidence': 0.7, 'reasoning': 'Fallback: C√¢u h·ªèi t·ªïng qu√°t'}

# --- Product Specialist Agent ---
class ProductSpecialistAgent(BaseAgent):
    def __init__(self, model: genai.GenerativeModel, vector_store: FAISS):
        super().__init__(AgentType.PRODUCT_SPECIALIST, model)
        self.vector_store = vector_store
        self.specialist_prompt = """
        B·∫°n l√† Product Specialist Agent c·ªßa EKS - chuy√™n gia s√¢u v·ªÅ c√°c s·∫£n ph·∫©m m·ªπ ph·∫©m. 
        B·∫°n c√≥ quy·ªÅn truy c·∫≠p v√†o c∆° s·ªü d·ªØ li·ªáu chi ti·∫øt v·ªÅ t·∫•t c·∫£ s·∫£n ph·∫©m EKS.

        **Th√¥ng tin s·∫£n ph·∫©m t·ª´ database:**
        ---
        {context}
        ---

        **C√¢u h·ªèi t·ª´ kh√°ch h√†ng:**
        {query}

        **Chuy√™n m√¥n c·ªßa b·∫°n:**
        - Ph√¢n t√≠ch th√†nh ph·∫ßn chi ti·∫øt
        - Gi·∫£i th√≠ch c∆° ch·∫ø ho·∫°t ƒë·ªông
        - H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng ch√≠nh x√°c
        - C·∫£nh b√°o ch·ªëng ch·ªâ ƒë·ªãnh
        - T∆∞ v·∫•n b·∫£o qu·∫£n v√† l∆∞u √Ω

        **C√°ch tr·∫£ l·ªùi:**
        1. **X∆∞ng h√¥**: "T√¥i l√† chuy√™n gia s·∫£n ph·∫©m EKS"
        2. **Phong c√°ch**: Chuy√™n nghi·ªáp, chi ti·∫øt, d·ª±a tr√™n khoa h·ªçc
        3. **C·∫•u tr√∫c**: S·ª≠ d·ª•ng bullet points v√† headers ƒë·ªÉ d·ªÖ ƒë·ªçc
        4. **Tr√≠ch d·∫´n**: Lu√¥n n√™u r√µ t√™n s·∫£n ph·∫©m c·ª• th·ªÉ
        5. **ƒê·ªô tin c·∫≠y**: Ch·ªâ tr·∫£ l·ªùi d·ª±a tr√™n data c√≥ s·∫µn, th·ª´a nh·∫≠n n·∫øu kh√¥ng c√≥ th√¥ng tin

        **L∆∞u √Ω quan tr·ªçng**: N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin ch√≠nh x√°c trong database, 
        h√£y n√≥i r√µ "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin chi ti·∫øt v·ªÅ v·∫•n ƒë·ªÅ n√†y trong c∆° s·ªü d·ªØ li·ªáu s·∫£n ph·∫©m EKS."
        """
    
    def process(self, request: TaskRequest) -> AgentResponse:
        # Retrieve relevant product information
        context = self._get_product_context(request.query)
        
        return AgentResponse(
            content="", # S·∫Ω ƒë∆∞·ª£c fill b·ªüi streaming
            confidence=0.9,
            agent_type=self.agent_type,
            metadata={'context_size': len(context), 'source': 'product_database'}
        )
    
    def process_stream(self, request: TaskRequest):
        """Streaming version c·ªßa process method"""
        context = self._get_product_context(request.query)
        prompt = self.specialist_prompt.format(context="\n\n".join(context), query=request.query)
        
        yield from self._generate_stream_response(prompt)
    
    def _get_product_context(self, query: str, k: int = 5) -> List[str]:
        """L·∫•y context t·ª´ product vector store"""
        try:
            results = self.vector_store.similarity_search(query, k=k)
            return [doc.page_content for doc in results]
        except Exception as e:
            st.error(f"L·ªói khi truy xu·∫•t th√¥ng tin s·∫£n ph·∫©m: {e}")
            return []

# --- General Consultant Agent ---
class GeneralConsultantAgent(BaseAgent):
    def __init__(self, model: genai.GenerativeModel, vector_store: FAISS):
        super().__init__(AgentType.GENERAL_CONSULTANT, model)
        self.vector_store = vector_store
        self.consultant_prompt = """
        B·∫°n l√† General Consultant Agent c·ªßa EKS - t∆∞ v·∫•n vi√™n chuy√™n v·ªÅ th√¥ng tin t·ªïng qu√°t, 
        so s√°nh s·∫£n ph·∫©m v√† d·ªãch v·ª• kh√°ch h√†ng.

        **Th√¥ng tin tham kh·∫£o t·ª´ k·ªãch b·∫£n Q&A:**
        ---
        {context}
        ---

        **C√¢u h·ªèi t·ª´ kh√°ch h√†ng:**
        {query}

        **Chuy√™n m√¥n c·ªßa b·∫°n:**
        - So s√°nh v√† ƒë√°nh gi√° s·∫£n ph·∫©m
        - Th√¥ng tin v·ªÅ th∆∞∆°ng hi·ªáu EKS
        - Ch√≠nh s√°ch v√† d·ªãch v·ª•
        - H∆∞·ªõng d·∫´n mua h√†ng v√† li√™n h·ªá
        - T∆∞ v·∫•n l·ª±a ch·ªçn ph√π h·ª£p

        **C√°ch tr·∫£ l·ªùi:**
        1. **X∆∞ng h√¥**: "T√¥i l√† t∆∞ v·∫•n vi√™n EKS"
        2. **Phong c√°ch**: Th√¢n thi·ªán, d·ªÖ hi·ªÉu, t·∫≠p trung v√†o gi·∫£i ph√°p
        3. **∆Øu ti√™n**: N·∫øu c√≥ s·∫µn c√¢u tr·∫£ l·ªùi trong k·ªãch b·∫£n, s·ª≠ d·ª•ng y nguy√™n
        4. **Linh ho·∫°t**: C√≥ th·ªÉ tham kh·∫£o ki·∫øn th·ª©c chung n·∫øu c·∫ßn
        5. **H√†nh ƒë·ªông**: ƒê∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ v√† b∆∞·ªõc ti·∫øp theo

        **ƒê·∫∑c bi·ªát**: N·∫øu t√¨m th·∫•y c√¢u h·ªèi t∆∞∆°ng t·ª± trong k·ªãch b·∫£n, 
        h√£y s·ª≠ d·ª•ng ch√≠nh x√°c c√¢u tr·∫£ l·ªùi ƒë√≥.
        """
    
    def process(self, request: TaskRequest) -> AgentResponse:
        context = self._get_general_context(request.query)
        
        return AgentResponse(
            content="", # S·∫Ω ƒë∆∞·ª£c fill b·ªüi streaming
            confidence=0.8,
            agent_type=self.agent_type,
            metadata={'context_size': len(context), 'source': 'qa_script'}
        )
    
    def process_stream(self, request: TaskRequest):
        """Streaming version c·ªßa process method"""
        context = self._get_general_context(request.query)
        prompt = self.consultant_prompt.format(context="\n\n".join(context), query=request.query)
        
        yield from self._generate_stream_response(prompt)
    
    def _get_general_context(self, query: str, k: int = 3) -> List[str]:
        """L·∫•y context t·ª´ general Q&A vector store"""
        try:
            results = self.vector_store.similarity_search(query, k=k)
            return [doc.page_content for doc in results]
        except Exception as e:
            st.error(f"L·ªói khi truy xu·∫•t th√¥ng tin Q&A: {e}")
            return []

# --- Agent Manager ---
class AgentManager:
    def __init__(self):
        self.model = genai.GenerativeModel(GENERATIVE_MODEL)
        self.embedder = self._get_embedder()
        self.product_store = self._load_product_store()
        self.script_store = self._load_script_store()
        
        # Kh·ªüi t·∫°o c√°c agents
        self.router = RouterAgent(self.model)
        self.product_specialist = ProductSpecialistAgent(self.model, self.product_store)
        self.general_consultant = GeneralConsultantAgent(self.model, self.script_store)
        
        self.agents = {
            'product_specialist': self.product_specialist,
            'general_consultant': self.general_consultant
        }
    
    def _get_embedder(self):
        """T·∫£i v√† cache m√¥ h√¨nh embedding."""
        return get_embedder()
    
    def _load_product_store(self):
        """Load product FAISS store"""
        return load_or_create_product_faiss(self.embedder)
    
    def _load_script_store(self):
        """Load script FAISS store"""
        return load_or_create_script_faiss(self.embedder)
    
    def process_query(self, query: str) -> Dict[str, Any]:
        """X·ª≠ l√Ω query th√¥ng qua agent routing"""
        # 1. Router quy·∫øt ƒë·ªãnh agent
        request = TaskRequest(query=query)
        routing_decision = self.router.process(request)
        
        # 2. L·∫•y target agent
        target_agent_name = routing_decision['target_agent']
        target_agent = self.agents.get(target_agent_name, self.general_consultant)
        
        return {
            'agent': target_agent,
            'routing_info': routing_decision,
            'request': request
        }

# --- FAISS Loading Functions (fixed caching issues) ---
@st.cache_resource
def load_or_create_product_faiss(_embedder):
    """T·∫£i ho·∫∑c t·∫°o FAISS index cho d·ªØ li·ªáu s·∫£n ph·∫©m."""
    if os.path.exists(PRODUCT_FAISS_PATH):
        print(f"INFO: ƒêang t·∫£i ch·ªâ m·ª•c s·∫£n ph·∫©m t·ª´ '{PRODUCT_FAISS_PATH}'...")
        return FAISS.load_local(PRODUCT_FAISS_PATH, _embedder, allow_dangerous_deserialization=True)

    st.info("ƒêang t·∫°o ch·ªâ m·ª•c s·∫£n ph·∫©m...")
    print("INFO: B·∫Øt ƒë·∫ßu t·∫°o ch·ªâ m·ª•c FAISS cho s·∫£n ph·∫©m...")
    
    try:
        df = pd.read_csv(PRODUCT_CSV_FILE, encoding='utf-8')
        df.columns = [col.strip() for col in df.columns]

        documents = []
        fields_to_chunk = [
            "C√îNG D·ª§NG", "TH√ÄNH PH·∫¶N", "CH·ªà ƒê·ªäNH",
            "CH·ªêNG CH·ªà ƒê·ªäNH", "C√ÅCH D√ôNG", "B·∫¢O QU·∫¢N", "L∆ØU √ù KHI S·ª¨ D·ª§NG"
        ]

        for _, row in df.iterrows():
            product_name = row.get("S·∫¢N PH·∫®M", "Kh√¥ng r√µ t√™n")
            for field in fields_to_chunk:
                if field in row and pd.notna(row[field]):
                    chunk_content = f"S·∫£n ph·∫©m: {product_name}\nTh√¥ng tin v·ªÅ '{field}': {row[field]}"
                    documents.append(chunk_content)

        if not documents:
            st.error("L·ªói: Kh√¥ng th·ªÉ t·∫°o ƒë∆∞·ª£c chunks t·ª´ file s·∫£n ph·∫©m.")
            st.stop()
        
        print(f"INFO: ƒê√£ t·∫°o ƒë∆∞·ª£c {len(documents)} chunks s·∫£n ph·∫©m.")
        vectorstore = FAISS.from_texts(texts=documents, embedding=_embedder)
        vectorstore.save_local(PRODUCT_FAISS_PATH)
        print(f"INFO: L∆∞u ch·ªâ m·ª•c s·∫£n ph·∫©m th√†nh c√¥ng.")
        st.success("T·∫°o ch·ªâ m·ª•c s·∫£n ph·∫©m th√†nh c√¥ng!")
        return vectorstore
        
    except FileNotFoundError:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file '{PRODUCT_CSV_FILE}'.")
        st.stop()
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o ch·ªâ m·ª•c s·∫£n ph·∫©m: {e}")
        st.stop()

@st.cache_resource
def load_or_create_script_faiss(_embedder):
    """T·∫£i ho·∫∑c t·∫°o FAISS index cho k·ªãch b·∫£n Q&A."""
    if os.path.exists(SCRIPT_FAISS_PATH):
        print(f"INFO: ƒêang t·∫£i ch·ªâ m·ª•c k·ªãch b·∫£n t·ª´ '{SCRIPT_FAISS_PATH}'...")
        return FAISS.load_local(SCRIPT_FAISS_PATH, _embedder, allow_dangerous_deserialization=True)

    st.info("ƒêang t·∫°o ch·ªâ m·ª•c k·ªãch b·∫£n...")
    print("INFO: B·∫Øt ƒë·∫ßu t·∫°o ch·ªâ m·ª•c FAISS cho k·ªãch b·∫£n...")

    try:
        df = pd.read_csv(SCRIPT_CSV_FILE, encoding='utf-8')
        documents = [
            f"C√¢u h·ªèi: {row['C√¢u h·ªèi']}\nTr·∫£ l·ªùi: {row['Tr·∫£ l·ªùi']}"
            for _, row in df.iterrows() if pd.notna(row['C√¢u h·ªèi']) or pd.notna(row['Tr·∫£ l·ªùi'])
        ]
        
        if not documents:
            st.error("L·ªói: Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu h·ª£p l·ªá trong file k·ªãch b·∫£n.")
            st.stop()
        
        print(f"INFO: ƒê√£ t·∫°o ƒë∆∞·ª£c {len(documents)} documents k·ªãch b·∫£n.")
        vectorstore = FAISS.from_texts(texts=documents, embedding=_embedder)
        vectorstore.save_local(SCRIPT_FAISS_PATH)
        print(f"INFO: L∆∞u ch·ªâ m·ª•c k·ªãch b·∫£n th√†nh c√¥ng.")
        st.success("T·∫°o ch·ªâ m·ª•c k·ªãch b·∫£n th√†nh c√¥ng!")
        return vectorstore
        
    except FileNotFoundError:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file '{SCRIPT_CSV_FILE}'.")
        st.stop()
    except Exception as e:
        st.error(f"L·ªói khi t·∫°o ch·ªâ m·ª•c k·ªãch b·∫£n: {e}")
        st.stop()

# --- C·∫•u h√¨nh API ---
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except Exception:
    st.error("L·ªói: Vui l√≤ng thi·∫øt l·∫≠p GEMINI_API_KEY trong Streamlit Secrets.")
    st.stop()

# --- Kh·ªüi T·∫°o Agent Manager ---
@st.cache_resource
def get_agent_manager():
    return AgentManager()

# --- STREAMLIT UI ---
st.set_page_config(page_title="EKS Agent-to-Agent System", page_icon="ü§ñ")
st.title("ü§ñ EKS Agent-to-Agent AI System")
st.caption("H·ªá th·ªëng AI ƒëa t√°c nh√¢n v·ªõi Router Agent v√† Task Agents chuy√™n bi·ªát")

# Sidebar th√¥ng tin agents
with st.sidebar:
    st.header("üéØ System Agents")
    st.write("**üß≠ Router Agent**: Ph√¢n t√≠ch v√† ƒëi·ªÅu ph·ªëi")
    st.write("**üë®‚Äçüî¨ Product Specialist**: Chuy√™n gia s·∫£n ph·∫©m")
    st.write("**üë®‚Äçüíº General Consultant**: T∆∞ v·∫•n vi√™n chung")
    
    st.header("üîç Debug Mode")
    show_routing = st.checkbox("Hi·ªÉn th·ªã th√¥ng tin routing")

# Kh·ªüi t·∫°o Agent Manager
try:
    agent_manager = get_agent_manager()
    st.success("‚úÖ Agent system initialized successfully!")
except Exception as e:
    st.error(f"‚ùå L·ªói kh·ªüi t·∫°o agent system: {e}")
    st.stop()

# Chat Interface
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": """
üéâ **Ch√†o m·ª´ng ƒë·∫øn v·ªõi EKS Agent-to-Agent System!**

**H·ªá th·ªëng c√≥ 3 AI Agents:**
- üß≠ **Router Agent**: Ph√¢n t√≠ch c√¢u h·ªèi v√† ƒëi·ªÅu ph·ªëi
- üë®‚Äçüî¨ **Product Specialist**: Chuy√™n gia chi ti·∫øt v·ªÅ s·∫£n ph·∫©m
- üë®‚Äçüíº **General Consultant**: T∆∞ v·∫•n vi√™n cho c√¢u h·ªèi chung

**B·∫°n c√≥ th·ªÉ h·ªèi:**
- Chi ti·∫øt v·ªÅ s·∫£n ph·∫©m (th√†nh ph·∫ßn, c√¥ng d·ª•ng, c√°ch d√πng...)
- So s√°nh s·∫£n ph·∫©m, th√¥ng tin th∆∞∆°ng hi·ªáu
- Ch√≠nh s√°ch, d·ªãch v·ª•, ƒë·ªãa ch·ªâ mua h√†ng

H√£y ƒë·∫∑t c√¢u h·ªèi ƒë·ªÉ tr·∫£i nghi·ªám h·ªá th·ªëng AI th√¥ng minh! üòä
        """}
    ]

# Hi·ªÉn th·ªã chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat input
if prompt := st.chat_input("H·ªèi EKS Agent System..."):
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Process with Agent-to-Agent system
    with st.chat_message("assistant"):
        with st.spinner("üß≠ Router Agent ƒëang ph√¢n t√≠ch..."):
            # 1. Get routing decision
            processing_result = agent_manager.process_query(prompt)
            agent = processing_result['agent']
            routing_info = processing_result['routing_info']
            request = processing_result['request']
            
            # 2. Show routing info if debug enabled
            if show_routing:
                with st.expander("üîç Agent Routing Information"):
                    st.json({
                        "selected_agent": routing_info['target_agent'],
                        "confidence": routing_info['confidence'],
                        "reasoning": routing_info['reasoning']
                    })
            
            # 3. Display which agent is responding
            agent_emoji = "üë®‚Äçüî¨" if agent.agent_type == AgentType.PRODUCT_SPECIALIST else "üë®‚Äçüíº"
            agent_name = "Product Specialist" if agent.agent_type == AgentType.PRODUCT_SPECIALIST else "General Consultant"
            
            st.write(f"{agent_emoji} **{agent_name} Agent** ƒëang x·ª≠ l√Ω...")
            
            # 4. Stream response from selected agent
            response_generator = agent.process_stream(request)
            full_response = st.write_stream(response_generator)

    # Add assistant response to history
    st.session_state.messages.append({"role": "assistant", "content": full_response})