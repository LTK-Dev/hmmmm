import streamlit as st
import pandas as pd
import os
import google.generativeai as genai
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from enum import Enum
import json

# Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t cho FAISS vÃ  LangChain
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_core.prompts import ChatPromptTemplate

# --- Data Classes vÃ  Enums ---
class AgentType(Enum):
    ROUTER = "router"
    PRODUCT_SPECIALIST = "product_specialist"
    GENERAL_CONSULTANT = "general_consultant"

@dataclass
class AgentResponse:
    content: str
    confidence: float
    agent_type: AgentType
    metadata: Dict[str, Any] = None

@dataclass
class TaskRequest:
    query: str
    context: List[str] = None
    metadata: Dict[str, Any] = None

# --- Cáº¥u hÃ¬nh ---
PRODUCT_CSV_FILE = 'EKS.csv'
SCRIPT_CSV_FILE = 'EKS_ques.csv'
PRODUCT_FAISS_PATH = "faiss_index_product"
SCRIPT_FAISS_PATH = "faiss_index_script"
EMBEDDER_MODEL = 'intfloat/multilingual-e5-base'
GENERATIVE_MODEL = 'gemini-2.0-flash'

# --- Base Agent Class ---
class BaseAgent:
    def __init__(self, agent_type: AgentType, model: genai.GenerativeModel):
        self.agent_type = agent_type
        self.model = model
        self.name = agent_type.value
    
    def process(self, request: TaskRequest) -> AgentResponse:
        """Base method Ä‘á»ƒ xá»­ lÃ½ request - sáº½ Ä‘Æ°á»£c override bá»Ÿi cÃ¡c agent con"""
        raise NotImplementedError("Subclasses must implement process method")
    
    def _generate_stream_response(self, prompt: str):
        """Helper method Ä‘á»ƒ generate streaming response"""
        try:
            response_stream = self.model.generate_content(prompt, stream=True)
            for chunk in response_stream:
                if chunk.text:
                    yield chunk.text
        except Exception as e:
            st.error(f"Lá»—i khi generate response tá»« {self.name}: {e}")
            yield f"Xin lá»—i, {self.name} gáº·p lá»—i khi xá»­ lÃ½ yÃªu cáº§u."

# --- Router Agent ---
class RouterAgent(BaseAgent):
    def __init__(self, model: genai.GenerativeModel):
        super().__init__(AgentType.ROUTER, model)
        self.routing_prompt = """
        Báº¡n lÃ  Router Agent cá»§a há»‡ thá»‘ng EKS AI Assistant. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  phÃ¢n tÃ­ch cÃ¢u há»i vÃ  quyáº¿t Ä‘á»‹nh agent nÃ o sáº½ xá»­ lÃ½.

        **CÃ¡c Agent cÃ³ sáºµn:**
        1. **product_specialist**: ChuyÃªn gia sáº£n pháº©m - xá»­ lÃ½ cÃ¢u há»i vá»:
           - ThÃ´ng tin chi tiáº¿t sáº£n pháº©m (cÃ´ng dá»¥ng, thÃ nh pháº§n, cÃ¡ch dÃ¹ng)
           - Chá»‰ Ä‘á»‹nh, chá»‘ng chá»‰ Ä‘á»‹nh cá»§a sáº£n pháº©m
           - Báº£o quáº£n, lÆ°u Ã½ khi sá»­ dá»¥ng
           - TÃ¡c dá»¥ng phá»¥, liá»u lÆ°á»£ng

        2. **general_consultant**: TÆ° váº¥n viÃªn chung - xá»­ lÃ½ cÃ¢u há»i vá»:
           - So sÃ¡nh nhiá»u sáº£n pháº©m
           - ThÃ´ng tin vá» cÃ´ng ty, thÆ°Æ¡ng hiá»‡u
           - ChÃ­nh sÃ¡ch, dá»‹ch vá»¥ khÃ¡ch hÃ ng
           - Äá»‹a chá»‰ mua hÃ ng, liÃªn há»‡
           - CÃ¢u há»i tá»•ng quÃ¡t vá» ngÃ nh má»¹ pháº©m

        **CÃ¢u há»i cáº§n phÃ¢n tÃ­ch:**
        "{query}"

        **YÃªu cáº§u:**
        Tráº£ lá»i CHÃNH XÃC theo format JSON sau:
        {{
            "agent": "product_specialist" hoáº·c "general_consultant",
            "confidence": sá»‘ tá»« 0.0 Ä‘áº¿n 1.0,
            "reasoning": "lÃ½ do ngáº¯n gá»n cho quyáº¿t Ä‘á»‹nh"
        }}

        CHá»ˆ tráº£ lá»i JSON, khÃ´ng thÃªm text nÃ o khÃ¡c.
        """
    
    def process(self, request: TaskRequest) -> Dict[str, Any]:
        """PhÃ¢n tÃ­ch vÃ  route cÃ¢u há»i Ä‘áº¿n agent phÃ¹ há»£p"""
        try:
            prompt = self.routing_prompt.format(query=request.query)
            response = self.model.generate_content(prompt)
            
            # Parse JSON response
            routing_decision = json.loads(response.text.strip())
            
            return {
                'target_agent': routing_decision.get('agent', 'general_consultant'),
                'confidence': routing_decision.get('confidence', 0.5),
                'reasoning': routing_decision.get('reasoning', 'PhÃ¢n tÃ­ch tá»± Ä‘á»™ng')
            }
            
        except json.JSONDecodeError:
            # Fallback náº¿u JSON parsing tháº¥t báº¡i
            st.warning("Router Agent tráº£ vá» format khÃ´ng Ä‘Ãºng, sá»­ dá»¥ng fallback logic")
            return self._fallback_routing(request.query)
        except Exception as e:
            st.error(f"Lá»—i Router Agent: {e}")
            return self._fallback_routing(request.query)
    
    def _fallback_routing(self, query: str) -> Dict[str, Any]:
        """Fallback routing logic náº¿u AI routing tháº¥t báº¡i"""
        query_lower = query.lower()
        
        product_keywords = ['sáº£n pháº©m', 'cÃ´ng dá»¥ng', 'thÃ nh pháº§n', 'cÃ¡ch dÃ¹ng', 'chá»‰ Ä‘á»‹nh', 'tÃ¡c dá»¥ng']
        general_keywords = ['so sÃ¡nh', 'cÃ´ng ty', 'mua á»Ÿ Ä‘Ã¢u', 'giÃ¡', 'chÃ­nh sÃ¡ch']
        
        product_score = sum(1 for kw in product_keywords if kw in query_lower)
        general_score = sum(1 for kw in general_keywords if kw in query_lower)
        
        if product_score > general_score:
            return {'target_agent': 'product_specialist', 'confidence': 0.7, 'reasoning': 'Fallback: PhÃ¡t hiá»‡n tá»« khÃ³a sáº£n pháº©m'}
        else:
            return {'target_agent': 'general_consultant', 'confidence': 0.7, 'reasoning': 'Fallback: CÃ¢u há»i tá»•ng quÃ¡t'}

# --- Product Specialist Agent ---
class ProductSpecialistAgent(BaseAgent):
    def __init__(self, model: genai.GenerativeModel, vector_store: FAISS):
        super().__init__(AgentType.PRODUCT_SPECIALIST, model)
        self.vector_store = vector_store
        self.specialist_prompt = """
        Báº¡n lÃ  Product Specialist Agent cá»§a EKS - chuyÃªn gia sÃ¢u vá» cÃ¡c sáº£n pháº©m má»¹ pháº©m. 
        Báº¡n cÃ³ quyá»n truy cáº­p vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u chi tiáº¿t vá» táº¥t cáº£ sáº£n pháº©m EKS.

        **ThÃ´ng tin sáº£n pháº©m tá»« database:**
        ---
        {context}
        ---

        **CÃ¢u há»i tá»« khÃ¡ch hÃ ng:**
        {query}

        **ChuyÃªn mÃ´n cá»§a báº¡n:**
        - PhÃ¢n tÃ­ch thÃ nh pháº§n chi tiáº¿t
        - Giáº£i thÃ­ch cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng
        - HÆ°á»›ng dáº«n sá»­ dá»¥ng chÃ­nh xÃ¡c
        - Cáº£nh bÃ¡o chá»‘ng chá»‰ Ä‘á»‹nh
        - TÆ° váº¥n báº£o quáº£n vÃ  lÆ°u Ã½

        **CÃ¡ch tráº£ lá»i:**
        1. **XÆ°ng hÃ´**: "TÃ´i lÃ  chuyÃªn gia sáº£n pháº©m EKS"
        2. **Phong cÃ¡ch**: ChuyÃªn nghiá»‡p, chi tiáº¿t, dá»±a trÃªn khoa há»c
        3. **Cáº¥u trÃºc**: Sá»­ dá»¥ng bullet points vÃ  headers Ä‘á»ƒ dá»… Ä‘á»c
        4. **TrÃ­ch dáº«n**: LuÃ´n nÃªu rÃµ tÃªn sáº£n pháº©m cá»¥ thá»ƒ
        5. **Äá»™ tin cáº­y**: Chá»‰ tráº£ lá»i dá»±a trÃªn data cÃ³ sáºµn, thá»«a nháº­n náº¿u khÃ´ng cÃ³ thÃ´ng tin

        **LÆ°u Ã½ quan trá»ng**: Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin chÃ­nh xÃ¡c trong database, 
        hÃ£y nÃ³i rÃµ "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin chi tiáº¿t vá» váº¥n Ä‘á» nÃ y trong cÆ¡ sá»Ÿ dá»¯ liá»‡u sáº£n pháº©m EKS."
        """
    
    def process(self, request: TaskRequest) -> AgentResponse:
        # Retrieve relevant product information
        context = self._get_product_context(request.query)
        
        return AgentResponse(
            content="", # Sáº½ Ä‘Æ°á»£c fill bá»Ÿi streaming
            confidence=0.9,
            agent_type=self.agent_type,
            metadata={'context_size': len(context), 'source': 'product_database'}
        )
    
    def process_stream(self, request: TaskRequest):
        """Streaming version cá»§a process method"""
        context = self._get_product_context(request.query)
        prompt = self.specialist_prompt.format(context="\n\n".join(context), query=request.query)
        
        yield from self._generate_stream_response(prompt)
    
    def _get_product_context(self, query: str, k: int = 5) -> List[str]:
        """Láº¥y context tá»« product vector store"""
        try:
            results = self.vector_store.similarity_search(query, k=k)
            return [doc.page_content for doc in results]
        except Exception as e:
            st.error(f"Lá»—i khi truy xuáº¥t thÃ´ng tin sáº£n pháº©m: {e}")
            return []

# --- General Consultant Agent ---
class GeneralConsultantAgent(BaseAgent):
    def __init__(self, model: genai.GenerativeModel, vector_store: FAISS):
        super().__init__(AgentType.GENERAL_CONSULTANT, model)
        self.vector_store = vector_store
        self.consultant_prompt = """
        Báº¡n lÃ  General Consultant Agent cá»§a EKS - tÆ° váº¥n viÃªn chuyÃªn vá» thÃ´ng tin tá»•ng quÃ¡t, 
        so sÃ¡nh sáº£n pháº©m vÃ  dá»‹ch vá»¥ khÃ¡ch hÃ ng.

        **ThÃ´ng tin tham kháº£o tá»« ká»‹ch báº£n Q&A:**
        ---
        {context}
        ---

        **CÃ¢u há»i tá»« khÃ¡ch hÃ ng:**
        {query}

        **ChuyÃªn mÃ´n cá»§a báº¡n:**
        - So sÃ¡nh vÃ  Ä‘Ã¡nh giÃ¡ sáº£n pháº©m
        - ThÃ´ng tin vá» thÆ°Æ¡ng hiá»‡u EKS
        - ChÃ­nh sÃ¡ch vÃ  dá»‹ch vá»¥
        - HÆ°á»›ng dáº«n mua hÃ ng vÃ  liÃªn há»‡
        - TÆ° váº¥n lá»±a chá»n phÃ¹ há»£p

        **CÃ¡ch tráº£ lá»i:**
        1. **XÆ°ng hÃ´**: "TÃ´i lÃ  tÆ° váº¥n viÃªn EKS"
        2. **Phong cÃ¡ch**: ThÃ¢n thiá»‡n, dá»… hiá»ƒu, táº­p trung vÃ o giáº£i phÃ¡p
        3. **Æ¯u tiÃªn**: Náº¿u cÃ³ sáºµn cÃ¢u tráº£ lá»i trong ká»‹ch báº£n, sá»­ dá»¥ng y nguyÃªn
        4. **Linh hoáº¡t**: CÃ³ thá»ƒ tham kháº£o kiáº¿n thá»©c chung náº¿u cáº§n
        5. **HÃ nh Ä‘á»™ng**: ÄÆ°a ra lá»i khuyÃªn cá»¥ thá»ƒ vÃ  bÆ°á»›c tiáº¿p theo

        **Äáº·c biá»‡t**: Náº¿u tÃ¬m tháº¥y cÃ¢u há»i tÆ°Æ¡ng tá»± trong ká»‹ch báº£n, 
        hÃ£y sá»­ dá»¥ng chÃ­nh xÃ¡c cÃ¢u tráº£ lá»i Ä‘Ã³.
        """
    
    def process(self, request: TaskRequest) -> AgentResponse:
        context = self._get_general_context(request.query)
        
        return AgentResponse(
            content="", # Sáº½ Ä‘Æ°á»£c fill bá»Ÿi streaming
            confidence=0.8,
            agent_type=self.agent_type,
            metadata={'context_size': len(context), 'source': 'qa_script'}
        )
    
    def process_stream(self, request: TaskRequest):
        """Streaming version cá»§a process method"""
        context = self._get_general_context(request.query)
        prompt = self.consultant_prompt.format(context="\n\n".join(context), query=request.query)
        
        yield from self._generate_stream_response(prompt)
    
    def _get_general_context(self, query: str, k: int = 3) -> List[str]:
        """Láº¥y context tá»« general Q&A vector store"""
        try:
            results = self.vector_store.similarity_search(query, k=k)
            return [doc.page_content for doc in results]
        except Exception as e:
            st.error(f"Lá»—i khi truy xuáº¥t thÃ´ng tin Q&A: {e}")
            return []

# --- Agent Manager ---
class AgentManager:
    def __init__(self):
        self.model = genai.GenerativeModel(GENERATIVE_MODEL)
        self.embedder = self._get_embedder()
        self.product_store = self._load_product_store()
        self.script_store = self._load_script_store()
        
        # Khá»Ÿi táº¡o cÃ¡c agents
        self.router = RouterAgent(self.model)
        self.product_specialist = ProductSpecialistAgent(self.model, self.product_store)
        self.general_consultant = GeneralConsultantAgent(self.model, self.script_store)
        
        self.agents = {
            'product_specialist': self.product_specialist,
            'general_consultant': self.general_consultant
        }
    
    @st.cache_resource
    def _get_embedder(_self):
        """Táº£i vÃ  cache mÃ´ hÃ¬nh embedding."""
        return SentenceTransformerEmbeddings(
            model_name=EMBEDDER_MODEL,
            model_kwargs={'device': 'cpu'}
        )
    
    @st.cache_resource
    def _load_product_store(_self):
        """Load product FAISS store"""
        return load_or_create_product_faiss(_self.embedder)
    
    @st.cache_resource
    def _load_script_store(_self):
        """Load script FAISS store"""
        return load_or_create_script_faiss(_self.embedder)
    
    def process_query(self, query: str) -> Dict[str, Any]:
        """Xá»­ lÃ½ query thÃ´ng qua agent routing"""
        # 1. Router quyáº¿t Ä‘á»‹nh agent
        request = TaskRequest(query=query)
        routing_decision = self.router.process(request)
        
        # 2. Láº¥y target agent
        target_agent_name = routing_decision['target_agent']
        target_agent = self.agents.get(target_agent_name, self.general_consultant)
        
        return {
            'agent': target_agent,
            'routing_info': routing_decision,
            'request': request
        }

# --- FAISS Loading Functions (giá»¯ nguyÃªn tá»« version cÅ©) ---
@st.cache_resource
def load_or_create_product_faiss(embedder):
    """Táº£i hoáº·c táº¡o FAISS index cho dá»¯ liá»‡u sáº£n pháº©m."""
    if os.path.exists(PRODUCT_FAISS_PATH):
        return FAISS.load_local(PRODUCT_FAISS_PATH, embedder, allow_dangerous_deserialization=True)

    st.info("Äang táº¡o chá»‰ má»¥c sáº£n pháº©m...")
    try:
        df = pd.read_csv(PRODUCT_CSV_FILE, encoding='utf-8')
        df.columns = [col.strip() for col in df.columns]

        documents = []
        fields_to_chunk = [
            "CÃ”NG Dá»¤NG", "THÃ€NH PHáº¦N", "CHá»ˆ Äá»ŠNH",
            "CHá»NG CHá»ˆ Äá»ŠNH", "CÃCH DÃ™NG", "Báº¢O QUáº¢N", "LÆ¯U Ã KHI Sá»¬ Dá»¤NG"
        ]

        for _, row in df.iterrows():
            product_name = row.get("Sáº¢N PHáº¨M", "KhÃ´ng rÃµ tÃªn")
            for field in fields_to_chunk:
                if field in row and pd.notna(row[field]):
                    chunk_content = f"Sáº£n pháº©m: {product_name}\nThÃ´ng tin vá» '{field}': {row[field]}"
                    documents.append(chunk_content)

        vectorstore = FAISS.from_texts(texts=documents, embedding=embedder)
        vectorstore.save_local(PRODUCT_FAISS_PATH)
        return vectorstore
    except Exception as e:
        st.error(f"Lá»—i khi táº¡o chá»‰ má»¥c sáº£n pháº©m: {e}")
        st.stop()

@st.cache_resource
def load_or_create_script_faiss(embedder):
    """Táº£i hoáº·c táº¡o FAISS index cho ká»‹ch báº£n Q&A."""
    if os.path.exists(SCRIPT_FAISS_PATH):
        return FAISS.load_local(SCRIPT_FAISS_PATH, embedder, allow_dangerous_deserialization=True)

    st.info("Äang táº¡o chá»‰ má»¥c ká»‹ch báº£n...")
    try:
        df = pd.read_csv(SCRIPT_CSV_FILE, encoding='utf-8')
        documents = [
            f"CÃ¢u há»i: {row['CÃ¢u há»i']}\nTráº£ lá»i: {row['Tráº£ lá»i']}"
            for _, row in df.iterrows() if pd.notna(row['CÃ¢u há»i']) or pd.notna(row['Tráº£ lá»i'])
        ]
        
        vectorstore = FAISS.from_texts(texts=documents, embedding=embedder)
        vectorstore.save_local(SCRIPT_FAISS_PATH)
        return vectorstore
    except Exception as e:
        st.error(f"Lá»—i khi táº¡o chá»‰ má»¥c ká»‹ch báº£n: {e}")
        st.stop()

# --- Cáº¥u hÃ¬nh API ---
try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
except Exception:
    st.error("Lá»—i: Vui lÃ²ng thiáº¿t láº­p GEMINI_API_KEY trong Streamlit Secrets.")
    st.stop()

# --- Khá»Ÿi Táº¡o Agent Manager ---
@st.cache_resource
def get_agent_manager():
    return AgentManager()

# --- STREAMLIT UI ---
st.set_page_config(page_title="EKS Agent-to-Agent System", page_icon="ğŸ¤–")
st.title("ğŸ¤– EKS Agent-to-Agent AI System")
st.caption("Há»‡ thá»‘ng AI Ä‘a tÃ¡c nhÃ¢n vá»›i Router Agent vÃ  Task Agents chuyÃªn biá»‡t")

# Sidebar thÃ´ng tin agents
with st.sidebar:
    st.header("ğŸ¯ System Agents")
    st.write("**ğŸ§­ Router Agent**: PhÃ¢n tÃ­ch vÃ  Ä‘iá»u phá»‘i")
    st.write("**ğŸ‘¨â€ğŸ”¬ Product Specialist**: ChuyÃªn gia sáº£n pháº©m")
    st.write("**ğŸ‘¨â€ğŸ’¼ General Consultant**: TÆ° váº¥n viÃªn chung")
    
    st.header("ğŸ” Debug Mode")
    show_routing = st.checkbox("Hiá»ƒn thá»‹ thÃ´ng tin routing")

# Khá»Ÿi táº¡o Agent Manager
try:
    agent_manager = get_agent_manager()
    st.success("âœ… Agent system initialized successfully!")
except Exception as e:
    st.error(f"âŒ Lá»—i khá»Ÿi táº¡o agent system: {e}")
    st.stop()

# Chat Interface
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": """
ğŸ‰ **ChÃ o má»«ng Ä‘áº¿n vá»›i EKS Agent-to-Agent System!**

**Há»‡ thá»‘ng cÃ³ 3 AI Agents:**
- ğŸ§­ **Router Agent**: PhÃ¢n tÃ­ch cÃ¢u há»i vÃ  Ä‘iá»u phá»‘i
- ğŸ‘¨â€ğŸ”¬ **Product Specialist**: ChuyÃªn gia chi tiáº¿t vá» sáº£n pháº©m
- ğŸ‘¨â€ğŸ’¼ **General Consultant**: TÆ° váº¥n viÃªn cho cÃ¢u há»i chung

**Báº¡n cÃ³ thá»ƒ há»i:**
- Chi tiáº¿t vá» sáº£n pháº©m (thÃ nh pháº§n, cÃ´ng dá»¥ng, cÃ¡ch dÃ¹ng...)
- So sÃ¡nh sáº£n pháº©m, thÃ´ng tin thÆ°Æ¡ng hiá»‡u
- ChÃ­nh sÃ¡ch, dá»‹ch vá»¥, Ä‘á»‹a chá»‰ mua hÃ ng

HÃ£y Ä‘áº·t cÃ¢u há»i Ä‘á»ƒ tráº£i nghiá»‡m há»‡ thá»‘ng AI thÃ´ng minh! ğŸ˜Š
        """}
    ]

# Hiá»ƒn thá»‹ chat history
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat input
if prompt := st.chat_input("Há»i EKS Agent System..."):
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Process with Agent-to-Agent system
    with st.chat_message("assistant"):
        with st.spinner("ğŸ§­ Router Agent Ä‘ang phÃ¢n tÃ­ch..."):
            # 1. Get routing decision
            processing_result = agent_manager.process_query(prompt)
            agent = processing_result['agent']
            routing_info = processing_result['routing_info']
            request = processing_result['request']
            
            # 2. Show routing info if debug enabled
            if show_routing:
                with st.expander("ğŸ” Agent Routing Information"):
                    st.json({
                        "selected_agent": routing_info['target_agent'],
                        "confidence": routing_info['confidence'],
                        "reasoning": routing_info['reasoning']
                    })
            
            # 3. Display which agent is responding
            agent_emoji = "ğŸ‘¨â€ğŸ”¬" if agent.agent_type == AgentType.PRODUCT_SPECIALIST else "ğŸ‘¨â€ğŸ’¼"
            agent_name = "Product Specialist" if agent.agent_type == AgentType.PRODUCT_SPECIALIST else "General Consultant"
            
            st.write(f"{agent_emoji} **{agent_name} Agent** Ä‘ang xá»­ lÃ½...")
            
            # 4. Stream response from selected agent
            response_generator = agent.process_stream(request)
            full_response = st.write_stream(response_generator)

    # Add assistant response to history
    st.session_state.messages.append({"role": "assistant", "content": full_response})